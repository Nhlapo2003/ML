import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    cohen_kappa_score, f1_score, precision_score, recall_score
)
import joblib
import warnings

warnings.filterwarnings('ignore')
sns.set_style("whitegrid")

# --- Configuration ---
TRAIN_FILE_PATH = r"C:\Users\snhla\Downloads\data.xlsx"  # Update your file path
TARGET_COL_CANDIDATE = 'Target'

# --- 1. Load Data ---
def load_data(file_path):
    try:
        if file_path.endswith('.csv'):
            return pd.read_csv(file_path)
        elif file_path.endswith(('.xlsx', '.xls')):
            return pd.read_excel(file_path)
        else:
            return pd.read_csv(file_path)
    except Exception as e:
        print(f"‚ùå Error loading file: {e}")
        return None

# --- 2. Clean, Handle Missing Values, Outliers & Descriptive Stats ---
def clean_and_prepare_data(df, target_col):
    df.columns = df.columns.str.strip().str.replace('\t','').str.replace('\n','')

    # --- Missing Values ---
    missing_before = df.isnull().sum()
    total_missing = missing_before.sum()
    df_cleaned = df.dropna().copy()
    print(f"‚úÖ Removed {total_missing} missing values. Shape: {df_cleaned.shape}")

    # Missing values summary
    missing_summary = pd.DataFrame({
        'Missing_Values_Before': missing_before,
        'Missing_Values_After': df_cleaned.isnull().sum()
    })
    print("\nüìå Missing Values Summary (Top 37 Columns):")
    print(missing_summary.head(37))

    # Plot missing values
    missing_summary.head(37).plot(kind='bar', figsize=(10,5))
    plt.title("Missing Values Before and After Cleaning")
    plt.ylabel("Number of Missing Values")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Target column check & encode
    if target_col not in df_cleaned.columns:
        target_col = df_cleaned.columns[-1]
    le = None
    if df_cleaned[target_col].dtype == 'object':
        le = LabelEncoder()
        df_cleaned[target_col] = le.fit_transform(df_cleaned[target_col])
        print(f"üéØ Encoded target '{target_col}' into numeric labels.")

    # --- Outlier Handling ---
    numeric_cols = df_cleaned.select_dtypes(include=['int64', 'float64'])
    outlier_summary = []
    for col in numeric_cols.columns:
        if col == target_col:
            continue
        lower, upper = df_cleaned[col].quantile([0.01,0.99])
        before_min, before_max = df_cleaned[col].min(), df_cleaned[col].max()
        df_cleaned[col] = np.clip(df_cleaned[col], lower, upper)
        after_min, after_max = df_cleaned[col].min(), df_cleaned[col].max()
        outlier_summary.append({
            'Feature': col,
            'Min_Before': before_min, 'Max_Before': before_max,
            'Min_After': after_min, 'Max_After': after_max
        })

    outlier_summary_df = pd.DataFrame(outlier_summary)
    print("\nüìå Outlier Handling Summary (Top 37 Numeric Features):")
    print(outlier_summary_df.head(37))

    # Plot outlier changes
    sample_df = outlier_summary_df.head(37)
    plt.figure(figsize=(10,6))
    plt.scatter(sample_df['Feature'], sample_df['Min_Before'], color='red', label='Min Before')
    plt.scatter(sample_df['Feature'], sample_df['Max_Before'], color='blue', label='Max Before')
    plt.scatter(sample_df['Feature'], sample_df['Min_After'], color='orange', label='Min After', marker='x')
    plt.scatter(sample_df['Feature'], sample_df['Max_After'], color='green', label='Max After', marker='x')
    plt.title("Outlier Handling (Top 37 Numeric Features)")
    plt.ylabel("Value")
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # --- Descriptive Stats ---
    numeric_summary = numeric_cols.describe().T
    numeric_summary["skewness"] = numeric_cols.skew()
    numeric_summary["kurtosis"] = numeric_cols.kurtosis()
    print("\nüìà Descriptive Statistics (Top 37 Numeric Columns):")
    print(numeric_summary.head(37))

    return df_cleaned, target_col, le

# --- 3. Cross-Feature Engineering ---
def feature_crossing(df):
    df_cross = df.copy()

    # Example: Age x Scholarship holder
    if 'Age at enrollment' in df_cross.columns and 'Scholarship holder' in df_cross.columns:
        df_cross['age_scholarship'] = df_cross['Age at enrollment'].astype(str) + "_" + df_cross['Scholarship holder'].astype(str)

    # Example: Previous qualification grade x Admission grade
    if 'Previous qualification (grade)' in df_cross.columns and 'Admission grade' in df_cross.columns:
        df_cross['prevqual_admgrade'] = df_cross['Previous qualification (grade)'].astype(str) + "_" + df_cross['Admission grade'].astype(str)

    # Encode new cross features
    new_cross_cols = [col for col in df_cross.columns if '_' in col]
    for col in new_cross_cols:
        df_cross[col] = LabelEncoder().fit_transform(df_cross[col])

    return df_cross

# --- 4. Train Best Random Forest Model ---
def train_best_model(df_train, target_col):
    X = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)
    y = df_train[target_col]

    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.3, stratify=y, random_state=42
    )

    configs = [{'n_estimators': 50, 'max_depth': 8},
               {'n_estimators': 100, 'max_depth': 12},
               {'n_estimators': 150, 'max_depth': 16}]

    best_score, best_config = 0, None
    CV_FOLDS = 3

    for c in configs:
        rf = RandomForestClassifier(n_estimators=c['n_estimators'], max_depth=c['max_depth'],
                                    min_samples_split=5, min_samples_leaf=2,
                                    class_weight='balanced', random_state=42, n_jobs=-1)
        score = cross_val_score(rf, X_train, y_train, cv=CV_FOLDS, n_jobs=-1, scoring='accuracy').mean()
        if score > best_score:
            best_score, best_config = score, c

    final_model = RandomForestClassifier(
        **best_config, min_samples_split=5, min_samples_leaf=2,
        class_weight='balanced', random_state=42, n_jobs=-1
    )
    final_model.fit(X, y)

    y_val_pred = final_model.predict(X_val)
    print("\nModel Validation Metrics:")
    print(f"  Accuracy: {accuracy_score(y_val, y_val_pred):.4f}")
    print(classification_report(y_val, y_val_pred, zero_division=0))

    return final_model, X, y, X_val, y_val

# --- 5. Visualization & Confusion Matrix ---
def visualize_results(df_cleaned, X, y, model, le=None):
    fig, axs = plt.subplots(2, 2, figsize=(16, 12))
    axs = axs.flatten()

    # 1Ô∏è‚É£ Target Class Distribution
    sns.countplot(x=y, ax=axs[0], palette='viridis')
    axs[0].set_title('1. Target Class Distribution')

    # 2Ô∏è‚É£ Feature Importances
    importances = model.feature_importances_
    feature_names = X.columns
    feature_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
    feature_df = feature_df.sort_values('Importance', ascending=False).head(37)
    sns.barplot(x='Importance', y='Feature', data=feature_df, ax=axs[1], palette='mako')
    axs[1].set_title('2. Top 37 Feature Importances')

    # 3Ô∏è‚É£ Numerical Feature Correlation Heatmap
    numeric_df = df_cleaned.select_dtypes(include=['number']).drop(columns=[y.name], errors='ignore')
    if not numeric_df.empty:
        corr = numeric_df.corr()
        mask = np.triu(corr)
        sns.heatmap(corr, annot=False, cmap='coolwarm', ax=axs[2], mask=mask, cbar_kws={'shrink':0.8})
        axs[2].set_title('3. Numerical Feature Correlation Heatmap')

    # 4Ô∏è‚É£ Final Confusion Matrix (Full Dataset)
    y_pred_full = model.predict(X)
    cm = confusion_matrix(y, y_pred_full)
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
    class_names = le.classes_ if le is not None else [str(i) for i in range(cm.shape[0])]

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=axs[3])
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            axs[3].text(j + 0.5, i + 0.5, f"{cm_percent[i, j]:.1f}%", 
                        horizontalalignment='center', verticalalignment='center', color='red', fontsize=10)
    axs[3].set_xlabel("Predicted Label")
    axs[3].set_ylabel("True Label")
    axs[3].set_title("4. Final Confusion Matrix (Full Dataset)")

    plt.tight_layout()
    plt.show()

# --- 6. Evaluation Table ---
def evaluation_summary(y_true, y_pred, le=None):
    class_names = le.classes_ if le is not None else [str(i) for i in np.unique(y_true)]
    precision = precision_score(y_true, y_pred, average=None, zero_division=0)
    recall = recall_score(y_true, y_pred, average=None, zero_division=0)
    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)

    summary_df = pd.DataFrame({
        'Class': class_names,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1
    })
    print("\nüìä Evaluation Summary by Class:")
    print(summary_df)

    print(f"\nOverall Accuracy: {accuracy_score(y_true, y_pred):.4f}")
    print(f"Weighted F1 Score: {f1_score(y_true, y_pred, average='weighted', zero_division=0):.4f}")
    print(f"Cohen's Kappa: {cohen_kappa_score(y_true, y_pred):.4f}")

# --- 7. Main Execution ---
if __name__ == '__main__':
    print("="*80)
    print("üéì STUDENT DROPOUT PREDICTION PIPELINE WITH CROSS-FEATURES")
    print("="*80)

    df_train = load_data(TRAIN_FILE_PATH)
    if df_train is not None:
        df_cleaned, target_col, le = clean_and_prepare_data(df_train, TARGET_COL_CANDIDATE)

        # --- Feature crossing ---
        df_crossed = feature_crossing(df_cleaned)

        # --- Train model ---
        model, X_full, y_full, X_val, y_val = train_best_model(df_crossed, target_col)

        # Save artifacts
        joblib.dump({'model': model, 'encoder': le}, 'model_and_encoder.joblib')
        joblib.dump(X_full.columns.tolist(), 'model_columns.joblib')

        # Visualize results & confusion matrix
        visualize_results(df_crossed, X_full, y_full, model, le)

        # --- Final Evaluation ---
        y_val_pred = model.predict(X_full)
        evaluation_summary(y_full, y_val_pred, le)
        print("="*50)
